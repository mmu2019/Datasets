import numpy as np
from netCDF4 import Dataset
import pylab as plt
import os
import time
import datetime
from mpl_toolkits.basemap import Basemap
import netCDF4 as nc
import math
from urllib.request import urlretrieve
from scipy.interpolate import griddata

# set up Data directory
DataDir = "/Users/mingquan/newDATA"

# Set general information for the data source
remote_source = "https://doi.org/doi:10.17871/FLUXCOM_EnergyFluxes_v1"
gist_source = "https://github.com/mmu2019/Datasets/blob/master/read-sh-fluxcom.py"
local_source = DataDir + '/FluxCom/sh/H.RS_METEO.EBC-ALL.MLM-ALL.METEO-GSWP3.720_360.monthly.YYYY.nc'
stamp1 = '2019-05-07'

datestr = str(datetime.datetime.now())
TmpStr  = datestr.split(' ')
stamp2  = TmpStr[0]

print(datestr)
print(stamp2)

instit = "Department Biogeochemical Integration, Max Planck Institute for Biogeochemistry, Germany"

period = "1980-01 through 2014-12"
origtr = "monthly"
origsr = "0.5 degree"
origut = "MJ/m2/day"
finltr = "monthly"
finlsr = "0.5 degree"
finlut = "watt/m2"

# Create temporal dimension
nyears    = 35
nmonth    = 12
smonth = np.asarray(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12'])
month_bnd = np.asarray([0,31,59,90,120,151,181,212,243,273,304,334,365],dtype=float)
tbnd  = np.asarray([((np.arange(nyears)*365)[:,np.newaxis]+month_bnd[:-1]).flatten(),
                    ((np.arange(nyears)*365)[:,np.newaxis]+month_bnd[+1:]).flatten()]).T
tbnd += (1980-1850)*365
tbnd.shape
t     = tbnd.mean(axis=1)

# Create spatial dimension
res    = 0.5
latbnd = np.asarray([np.arange(- 90    , 90     ,res),
                     np.arange(- 90+res, 90+0.01,res)]).T
lonbnd = np.asarray([np.arange(-180    ,180     ,res),
                     np.arange(-180+res,180+0.01,res)]).T
lat    = latbnd.mean(axis=1)
lon    = lonbnd.mean(axis=1)

ntim = t.size
nlat = lat.size
nlon = lon.size

# Create some fake data
data   = np.ma.masked_array(np.random.rand(t.size,lat.size,lon.size))
area   = np.ma.masked_array(np.random.rand(lat.size,lon.size))

data[:,:,:] = 0.0
area[:,:]   = 0.0

nlat = lat.size
nlon = lon.size

ij = 0
for i in range(nyears):

    year    = i + 1980

    print(year)

    # read single netCDF file
    filename = DataDir + '/FluxCom/sh/H.RS_METEO.EBC-ALL.MLM-ALL.METEO-GSWP3.720_360.monthly.' + str(year) + '.nc'
    print(filename)
    flx=Dataset(filename,'r',format='NETCDF4')
    data0 = flx.variables['H']
    lats  = flx.variables['lat']

    long_name = data0.long_name
    #long_name = "latent heat"

    for j in range(nmonth):

        data[ij,:,:] = data0[j,::-1,:]

        ij = ij + 1

# convert unit from MJ/m2/day to watt/m2
data[:,:,:] = data[:,:,:]*1.e6/(24*3600)

print(t.shape)
print(data0.shape)
print(data.shape)

data_min = data.min()
data_max = data.max()

with Dataset(DataDir + "/sh.nc", mode="w") as dset:

    # Create netCDF dimensions
    dset.createDimension("time",size=  t.size)
    dset.createDimension("lat" ,size=lat.size)
    dset.createDimension("lon" ,size=lon.size)
    dset.createDimension("nb"  ,size=2       )

    # Create netCDF variables
    T  = dset.createVariable("time"       ,t.dtype   ,("time"     ))
    TB = dset.createVariable("time_bounds",t.dtype   ,("time","nb"))
    X  = dset.createVariable("lat"        ,lat.dtype ,("lat"      ))
    XB = dset.createVariable("lat_bounds" ,lat.dtype ,("lat","nb" ))
    Y  = dset.createVariable("lon"        ,lon.dtype ,("lon"      ))
    YB = dset.createVariable("lon_bounds" ,lon.dtype ,("lon","nb" ))
    D  = dset.createVariable("sh"        ,data.dtype,("time","lat","lon"), fill_value = -999.)

    print(D.shape)

    # Load data and encode attributes
    # time
    T [...]    = t
    T.units    = "days since 1850-01-01"
    T.calendar = "noleap"
    T.bounds   = "time_bounds"
    TB[...]    = tbnd
    T.standard_name = "time"
    T.long_name     = "time"

    # lat
    X [...]    = lat
    X.units    = "degrees_north"
    XB[...]    = latbnd
    X.standard_name = "latitude"
    X.long_name     = "latitude"

    # lon
    Y [...]    = lon
    Y.units    = "degrees_east"
    YB[...]    = lonbnd
    Y.standard_name = "longitude"
    Y.long_name     = "longitude"

    # data
    D[...] = data
    D.units = "watt/m2"
    D.standard_name = "sensible heat flux"
    D.long_name     = long_name
    D.actual_range = np.asarray([data_min,data_max])
    
    dset.title = "FLUXCOM (RS+METEO) Global Land Energy Fluxes using GSWP3 climate data"
    dset.version = "1"
    dset.institutions = instit
    dset.source = "Data generated by machine learning to merge energy flux measurements from FLUXNET eddy covariance towers with MODIS remote sensing and GSWP3v1 meteorological data (RS+METEO)"
    dset.history = """
%s: downloaded source from %s;
%s: converted to netCDF with %s""" % (stamp1, remote_source, stamp2, gist_source)
    dset.references  = """
@ARTICLE{Jung2019,
  author = {Jung, M., S. Koirala, U. Weber, K. Ichii, F. Gans, G. Camps-Valls, D. Papale, C. Schwalm, G. Tramontana, M. Reichstein},
  title = {The FLUXCOM ensemble of global land-atmosphere energy fluxes},
  journal = {Scientific Data},
  year = {2019},
  number = {submitted},
  page = {1-12},
  doi = {https://arxiv.org/abs/1812.04951}
}
@ARTICLE{Tramontana2016,
  author = {Tramontana, G., M. Jung, C.R. Schwalm, K. Ichii, G. Camps-Valls, B. Raduly, M. Reichstein, M.A. Arain, A. Cescatti, G. Kiely, L. Merbold, P. Serrano-Ortiz, S. Sickert, S. Wolf, and D. Papale},
  title = {Predicting carbon dioxide and energy fluxes across global FLUXNET sites with regression algorithms},
  journal = {Biogeosciences},
  year = {2016},
  number = {13},
  page = {4291-4313},
  doi = {https://doi.org/10.5194/bg-13-4291-2016}
}"""
    dset.comments = """
time_period: %s; original_temporal_resolution: %s; original_spatial_resolution: %s; original_units: %s; final_temporal_resolution: %s; final_spatial_resolution: %s; final_units: %s""" % (period, origtr, origsr, origut, finltr, finlsr, finlut)
    dset.convention = "CF-1.7"
